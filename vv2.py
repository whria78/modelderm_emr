import subprocess
import sys

def restart_script():
    print("[ì•Œë¦¼] í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í›„ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¬ì‹¤í–‰í•©ë‹ˆë‹¤...")
    python_exe = sys.executable
    script = sys.argv[0]
    args = sys.argv[1:]
    # ìƒˆ í”„ë¡œì„¸ìŠ¤ë¡œ ì¬ì‹¤í–‰
    subprocess.Popen([python_exe, script] + args)
    sys.exit(0)

def install_and_restart_if_needed(package, import_name=None):
    import_name = import_name or package
    try:
        __import__(import_name)
    except ImportError:
        print(f"[ì„¤ì¹˜ ì¤‘] {package} ...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", package])
        restart_script()


# í•„ìˆ˜ íŒ¨í‚¤ì§€ ë¦¬ìŠ¤íŠ¸
packages = [
    ("numpy", None),
    ("sd", None),
    ("sounddevice", None),
    ("pyperclip", None),
    ("requests", None),
    ("webrtcvad", None),
    ("pywin32", None),
    ("pyautogui", None)
]

for pkg, name in packages:
    install_and_import(pkg, name)


import win32gui

def list_all_windows():
    def enum_handler(hwnd, result):
        if win32gui.IsWindowVisible(hwnd):
            title = win32gui.GetWindowText(hwnd)
            if title:  # ë¹ˆ ë¬¸ìì—´ ì œì™¸
                result.append((hwnd, title))
    windows = []
    win32gui.EnumWindows(enum_handler, windows)
    return windows

# ì‹¤í–‰ ì‹œ ëª¨ë“  ìœˆë„ìš° ì¶œë ¥
for hwnd, title in list_all_windows():
    print(f"HWND: {hwnd}, Title: {title}")

    
import os
import json
import tkinter as tk
import pyperclip
import sounddevice as sd
import numpy as np
import wave
import requests
import threading
import time
import subprocess
from datetime import datetime
from collections import deque
from threading import Lock

import tempfile
import webrtcvad
import contextlib
import struct

import win32gui
import pyautogui
import re

# ---------------- ìœˆë„ìš° ì œì–´ ----------------
def find_window(title_substring):
    def enum_handler(hwnd, result):
        if win32gui.IsWindowVisible(hwnd):
            window_text = win32gui.GetWindowText(hwnd)
            if title_substring in window_text:
                result.append(hwnd)
    windows = []
    win32gui.EnumWindows(enum_handler, windows)
    return windows

def activate_window(window_title_substring):
    windows = find_window(window_title_substring)
    if not windows:
        print(f'"{window_title_substring}" ì°½ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
        return None
    hwnd = windows[0]
    win32gui.SetForegroundWindow(hwnd)
    time.sleep(0.2)
    return hwnd

def send_key_to_window(window_title_substring, key):
    hwnd = activate_window(window_title_substring)
    if hwnd is None:
        return False
    time.sleep(0.1)
    pyautogui.press(key.lower())
    return True

def send_text_to_window(window_title_substring, text):
    hwnd = activate_window(window_title_substring)
    if hwnd is None:
        return False
    pyperclip.copy(text)
    time.sleep(0.1)
    pyautogui.hotkey('ctrl', 'v')
    return True


# ---------------- config ì½ê¸° ----------------
CONFIG_PATH = "config.json"

default_config = {
    "SAMPLE_RATE": 16000,
    "CHANNELS": 1,
    "BLOCK_SEC": 0.1,
    "CHUNK_SEC": 30,
    "CHUNK_RESET_SEC": 10,
    "LOUD_RMS_THRESHOLD": 0.005,
    "LOUD_REQUIRED_SEC": 5.0,
    "RMS_SMOOTHING": 0.9,
    "FFMPEG_PATH": "c:\\ffmpeg\\bin\\ffmpeg.exe",
    "WHISPER_SERVER_URL": "https://t1.modelderm.com/whisper",
    "SPEECH_SERVER_URL": "https://t1.modelderm.com/20b",
    "SPEECH_SERVER2_URL": "https://t1.modelderm.com/120b",
    "LANG": 'ko',
    "PROMPT": "í”¼ë¶€ê³¼ ì§„ë£Œ ë…¹ìŒì„ ë“£ê³  ì°¨íŒ…ìš©ìœ¼ë¡œ 1~4ì¤„, ë‹¨ë‹µì‹, ë§¤ìš° ì§§ê²Œ ìš”ì•½. ì˜ˆë¥¼ ë“¤ë©´ '3MA í—ˆë¦¬ì˜ ì•½í•œ ê°€ë ¤ì›€ì¦','ê¸°ê°„ì„ ëª¨ë¥´ëŠ” ì „ì‹ ì˜ ë°œì§„', 'r/o ëŒ€ìƒí¬ì§„','íƒ€ë³‘ì›ì—ì„œ ì•½ë³µìš©', '3ì¼í›„ ë‹¤ì‹œ ë‚´ì› í•„ìš”' ê°™ì€ ì‹ìœ¼ë¡œ ìš”ì•½í•´ì¤˜. :",
    "PROMPT2": "í”¼ë¶€ê³¼ ì§„ë£Œ ë…¹ìŒì„ ë“£ê³  ì˜ë£Œ ì°¨íŒ…ì„ í•´ì¤˜. ë˜ë„ë¡ì´ë©´ ì§§ê²Œ ë‹¨ë‹µì‹ìœ¼ë¡œ ë¬¸ì¥ì„ êµ¬ì„±í•´ì¤˜. ì˜ˆë¥¼ ë“¤ë©´ '3MA í—ˆë¦¬ì˜ ì•½í•œ ê°€ë ¤ì›€ì¦','ê¸°ê°„ì„ ëª¨ë¥´ëŠ” ì „ì‹ ì˜ ë°œì§„', 'r/o ëŒ€ìƒí¬ì§„','íƒ€ë³‘ì›ì—ì„œ ì•½ë³µìš©', '3ì¼í›„ ë‹¤ì‹œ ë‚´ì› í•„ìš”' ê°™ì€ ì‹ìœ¼ë¡œ ì°¨íŒ…í•´ì¤˜. ì—¬ëŸ¬ê°€ì§€ ë¬¸ì œë¡œ ë‚´ì›í•˜ì˜€ë‹¤ë©´ ê°ê°ì˜ ë¬¸ì œë³„ë¡œ ë‚˜ëˆ ì„œ ê¸°ìˆ í•˜ê³  ëŒ€í™”ì— ìˆëŠ” ì‚¬ì‹¤ë§Œ ê¸°ë¡í•´ì¤˜. :",
}

try:
    with open(CONFIG_PATH, "r", encoding="utf-8") as f:
        config = json.load(f)
except FileNotFoundError:
    config = default_config
    with open(CONFIG_PATH, "w", encoding="utf-8") as f:
        json.dump(default_config, f, ensure_ascii=False, indent=4)
except Exception as e:
    print(f"[ì˜¤ë¥˜] ì„¤ì • íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
    config = default_config

# ì„¤ì • ë³€ìˆ˜
SAMPLE_RATE = config.get("SAMPLE_RATE", default_config["SAMPLE_RATE"])
CHANNELS = config.get("CHANNELS", default_config["CHANNELS"])
BLOCK_SEC = config.get("BLOCK_SEC", default_config["BLOCK_SEC"])
CHUNK_SEC = config.get("CHUNK_SEC", default_config["CHUNK_SEC"])
CHUNK_RESET_SEC = config.get("CHUNK_RESET_SEC", default_config["CHUNK_RESET_SEC"])
LOUD_RMS_THRESHOLD = config.get("LOUD_RMS_THRESHOLD", default_config["LOUD_RMS_THRESHOLD"])
LOUD_REQUIRED_SEC = config.get("LOUD_REQUIRED_SEC", default_config["LOUD_REQUIRED_SEC"])
RMS_SMOOTHING = config.get("RMS_SMOOTHING", default_config["RMS_SMOOTHING"])

FFMPEG_PATH = config.get("FFMPEG_PATH", default_config["FFMPEG_PATH"])
WHISPER_SERVER_URL = config.get("WHISPER_SERVER_URL", default_config["WHISPER_SERVER_URL"])
SPEECH_SERVER_URL = config.get("SPEECH_SERVER_URL", default_config["SPEECH_SERVER_URL"])
SPEECH_SERVER2_URL = config.get("SPEECH_SERVER2_URL", default_config["SPEECH_SERVER2_URL"])
PROMPT = config.get("PROMPT", default_config["PROMPT"])
PROMPT2 = config.get("PROMPT2", default_config["PROMPT2"])
LANG = config.get("LANG", default_config["LANG"])


# ---------------- ì „ì—­ ìƒíƒœ ----------------
frames = []
frames_lock = Lock()
recording = True
volume_rms = 0.0
MAX_SUM=6
summaries = deque(maxlen=MAX_SUM)
transcript_all =""
transcript_all_list=[]

chunk_start_time = time.time()
is_processing = False


# ---------------- ìœ í‹¸ ----------------
def save_wav(filename, data_blocks, sample_rate):
    if not data_blocks:
        return
    data_np = np.concatenate(data_blocks, axis=0).astype(np.float32)
    with wave.open(filename, 'wb') as wf:
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(2)
        wf.setframerate(sample_rate)
        wf.writeframes((np.clip(data_np, -1.0, 1.0) * 32767).astype(np.int16).tobytes())

def convert_wav_to_mp3(wav_path):
    mp3_path = os.path.splitext(wav_path)[0] + ".mp3"
    try:
        subprocess.run(
            [FFMPEG_PATH, "-y", "-i", wav_path, "-codec:a", "libmp3lame", "-b:a", "320k", mp3_path],
            stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL,
            creationflags=getattr(subprocess, "CREATE_NO_WINDOW", 0)
        )
    except Exception as e:
        print("[FFmpeg ì˜¤ë¥˜]", e)
    return mp3_path

def calc_loud_seconds(blocks, threshold_rms):
    total = 0.0
    for b in blocks:
        if b.size == 0:
            continue
        rms = float(np.sqrt(np.mean(np.square(b.astype(np.float32)))))
        if rms > threshold_rms:
            total += len(b) / SAMPLE_RATE
    return total

def format_timestamp(seconds: float) -> str:
    m = int(seconds // 60)
    s = int(seconds % 60)
    return f"{m:02d}:{s:02d}"


# ---------------- ì„œë²„ í†µì‹  ----------------

def read_wave(path):
    with contextlib.closing(wave.open(path, 'rb')) as wf:
        sample_rate = wf.getframerate()
        pcm_data = wf.readframes(wf.getnframes())
        return pcm_data, sample_rate, wf.getnchannels(), wf.getsampwidth()

def write_wave(path, pcm_data, sample_rate, n_channels=1, sampwidth=2):
    with contextlib.closing(wave.open(path, 'wb')) as wf:
        wf.setnchannels(n_channels)
        wf.setsampwidth(sampwidth)
        wf.setframerate(sample_rate)
        wf.writeframes(pcm_data)

def vad_trim(wav_path, aggressiveness=2):
    pcm_data, sample_rate, n_channels, sampwidth = read_wave(wav_path)
    if n_channels != 1 or sampwidth != 2:
        raise ValueError("webrtcvad requires mono PCM16 audio")

    vad = webrtcvad.Vad(aggressiveness)
    frame_duration = 30  # ms
    frame_size = int(sample_rate * frame_duration / 1000) * 2  # 2 bytes per sample

    # í”„ë ˆì„ ë‹¨ìœ„ë¡œ ë¶„í• 
    frames = [pcm_data[i:i+frame_size] for i in range(0, len(pcm_data), frame_size)]
    voiced_frames = [f for f in frames if len(f) == frame_size and vad.is_speech(f, sample_rate)]

    if not voiced_frames:
        return wav_path  # ìŒì„± ì—†ëŠ” ê²½ìš° ì›ë³¸ ë°˜í™˜

    trimmed_pcm = b''.join(voiced_frames)
    tmp_fd, tmp_path = tempfile.mkstemp(suffix=".wav")
    os.close(tmp_fd)
    write_wave(tmp_path, trimmed_pcm, sample_rate, n_channels, sampwidth)
    return tmp_path

def send_to_whisper_server(wav_path, lang=LANG):
    start_time = time.time()
    
    try:
        # ìŒì„± êµ¬ê°„ë§Œ trim
        trimmed_path = vad_trim(wav_path)

        with open(trimmed_path, 'rb') as f:
            files = {'file': (os.path.basename(trimmed_path), f, 'audio/wav')}
            data = {'lang': lang}  # POST ë°ì´í„°ë¡œ language ì „ë‹¬
            response = requests.post(WHISPER_SERVER_URL, files=files, data=data, timeout=60)
            response.raise_for_status()
            data = response.json()
            transcript = data.get('transcript') or data.get('text') or ''
        
        elapsed = time.time() - start_time
        print(f"[Whisper server processing time] {elapsed:.2f}ì´ˆ")
        os.remove(trimmed_path)
        return transcript

    except Exception as e:
        print("Error sending to Whisper server:", e)
        return ""

def send_to_speech_server(text):
    global PROMPT
    return send_to_speech_server_ex(PROMPT,text,SPEECH_SERVER_URL)

def send_to_speech_server2(text):
    global PROMPT2
    return send_to_speech_server_ex(PROMPT2,text,SPEECH_SERVER2_URL)

def send_to_speech_server_ex(PROMPT,text,url):
    try:
        payload = {
            "messages": [
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": PROMPT + text}
            ]
        }
        headers = {"Content-Type": "application/json"}
        r = requests.post(url, json=payload, headers=headers, timeout=300)
        r.raise_for_status()
        data = r.json()
        response_text = data.get("choices", [{}])[0].get("message", {}).get("content", "")
        match = re.search(r"<\|channel\|>final<\|message\|>(.*)", response_text, re.S)
        if match:
            return match.group(1).strip()
        return response_text.strip()
    except Exception as e:
        print("[ìš”ì•½ ì˜¤ë¥˜]", e)
        return ""


# ---------------- ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ----------------
def process_chunk(data_blocks):
    global is_processing
    global transcript_all
    
    if not data_blocks:
        is_processing = False
        return

    loud_sec = calc_loud_seconds(data_blocks, LOUD_RMS_THRESHOLD)
    print(f"[ë¶„ì„] í° ì†Œë¦¬ ëˆ„ì  {loud_sec:.2f}s / ì„ê³„ {LOUD_REQUIRED_SEC:.2f}s")

    if loud_sec < LOUD_REQUIRED_SEC:
        is_processing = False
        return

    ts = datetime.now().strftime("record_%Y_%m_%d_%H_%M_%S")
    wav_path = f"{ts}.wav"
    save_wav(wav_path, data_blocks, SAMPLE_RATE)
    convert_wav_to_mp3(wav_path)

    transcript = send_to_whisper_server(wav_path)
    if transcript:
        transcript_all += '\n' + transcript
        summary = send_to_speech_server(transcript)
        if summary:
            summaries.appendleft(summary)
            try:
                root.after(0, update_summary_buttons)
            except:
                pass
    is_processing = False


# ---------------- ì˜¤ë””ì˜¤ ì½œë°± ----------------
def audio_callback(indata, frames_count, time_info, status):
    global volume_rms
    x = indata[:, 0] if indata.ndim > 1 else indata
    x = x.astype(np.float32)
    rms = float(np.sqrt(np.mean(np.square(x)))) if x.size else 0.0
    volume_rms = RMS_SMOOTHING * volume_rms + (1.0 - RMS_SMOOTHING) * rms
    with frames_lock:
        frames.append(x.copy().reshape(-1, 1))

def create_tooltip(widget, text):
    tooltip = None

    def on_enter(event):
        nonlocal tooltip
        x = event.x_root + 10
        y = event.y_root + 10
        tooltip = tk.Toplevel(widget)
        tooltip.wm_overrideredirect(True)  # ì°½ ì¥ì‹ ì œê±°
        tooltip.wm_geometry(f"+{x}+{y}")
        label = tk.Label(
            tooltip, text=text, justify="left",
            background="#ffffe0", relief="solid", borderwidth=1,
            font=("Arial", 9), wraplength=400
        )
        label.pack(ipadx=1)

    def on_leave(event):
        nonlocal tooltip
        if tooltip:
            tooltip.destroy()
            tooltip = None

    widget.bind("<Enter>", on_enter)
    widget.bind("<Leave>", on_leave)


def on_patient_process(text):
    """ë²„íŠ¼ í´ë¦­ ì‹œ ì‹¤í–‰"""
    root.title("Please Wait ...")
    result_text = send_to_speech_server2(text)
    if result_text.strip():
        pyperclip.copy(result_text)
        root.title("ğŸ“‹ text copied")
        print(result_text)
        
def record_loop():
    global chunk_start_time, next_chunk_time, is_processing, transcript_all,transcript_all_list
    try:
        blocksize = int(SAMPLE_RATE * BLOCK_SEC)
        with sd.InputStream(
            samplerate=SAMPLE_RATE,
            channels=CHANNELS,
            dtype='float32',
            blocksize=blocksize,
            callback=audio_callback,
            latency='low'
        ):
            chunk_start_time = time.time()
            next_chunk_time = chunk_start_time + CHUNK_SEC
            threshold_crossed = False

            while recording:
                time.sleep(0.05)
                now = time.time()

                if volume_rms > LOUD_RMS_THRESHOLD:
                    threshold_crossed = True

                elapsed = now - chunk_start_time


                if elapsed >= CHUNK_RESET_SEC and not threshold_crossed:
                    with frames_lock:
                        frames.clear()
                    if transcript_all != "":
                        print(transcript_all)

                        # ğŸ”½ ìƒˆë¡œìš´ ë²„íŠ¼ ìƒì„±
                        col_idx = 0
                        # ìµœê·¼ transcript ê°€ ì™¼ìª½ì´ ë˜ë„ë¡ insert
                        patient_buttons.insert(0, transcript_all)

                        # ê¸°ì¡´ ë²„íŠ¼ clear í›„ ë‹¤ì‹œ grid
                        for w in patient_frame.winfo_children():
                            w.destroy()
                        for idx, t_text in enumerate(patient_buttons):
                            btn = tk.Button(
                                patient_frame,
                                text="ğŸ“„",  # ë¬¸ì„œ ì•„ì´ì½˜
                                width=2, height=1,
                                command=lambda tt=t_text: on_patient_process(tt)
                            )
                            btn.grid(row=0, column=idx, padx=2, pady=2)
                            create_tooltip(btn, t_text)  # ë§ˆìš°ìŠ¤ ì˜¤ë²„ ì‹œ transcript ë‚´ìš© í‘œì‹œ

                        transcript_all_list.append(transcript_all)
                        transcript_all = ""


                    chunk_start_time = now
                    next_chunk_time = now + CHUNK_SEC
                    threshold_crossed = False
                    continue


                if now >= next_chunk_time:
                    with frames_lock:
                        data_chunk = frames.copy()
                        frames.clear()
                    is_processing = True
                    threading.Thread(
                        target=process_chunk,
                        args=(data_chunk,),
                        daemon=True
                    ).start()
                    chunk_start_time = now
                    next_chunk_time = now + CHUNK_SEC
                    threshold_crossed = False
    except Exception as e:
        print("[ë…¹ìŒ ì˜¤ë¥˜]", e)


# ---------------- GUI ----------------
# ---------------- ì°½ ìœ„ì¹˜ ì €ì¥ ----------------
POSITION_FILE = "window_position.json"
def load_window_position():
    if os.path.exists(POSITION_FILE):
        try:
            with open(POSITION_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
            return data.get("geometry")
        except Exception as e:
            print("Fail to load geometry:", e)
    return None

def save_window_position():
    try:
        geometry = root.geometry()
        with open(POSITION_FILE, "w", encoding="utf-8") as f:
            json.dump({"geometry": geometry}, f)
    except Exception as e:
        print("Fail to save geometry:", e)


root = tk.Tk()
root.title("recode & summarize")
root.attributes("-topmost", True)
root.resizable(False, False)
root.attributes('-toolwindow', True)  # ìœˆë„ìš° ìƒë‹¨ ë²„íŠ¼ì—ì„œ ìµœì†Œ/ìµœëŒ€ ì œê±°

last_geometry = load_window_position()
if last_geometry:
    root.geometry(last_geometry)
root.geometry("250x180")

summary_frame = tk.Frame(root)
summary_frame.pack(fill="both", expand=True, padx=10, pady=6)

# ğŸ”½ patient_frame ì€ grid ë°°ì¹˜ë¥¼ ìœ„í•´ ë³„ë„ row=0 ì‚¬ìš©
patient_frame = tk.Frame(root)
patient_frame.pack(fill="x", side="bottom", padx=5, pady=5)
patient_buttons = []  # ë²„íŠ¼ ê´€ë¦¬ìš©

def update_window_title():
    if is_processing:
        root.title("ğŸ“¤ processingâ€¦")
    else:
        elapsed = time.time() - chunk_start_time
        remaining = max(0, int(CHUNK_SEC - elapsed))
        root.title(f"ğŸ™ {volume_rms:.3f} | {remaining} secs")
    root.after(500, update_window_title)

def on_copy(text):
    pyperclip.copy(text)
    root.title("ğŸ“‹ copied")
    send_key_to_window("ì§„ë£Œì‹¤", "F2")
    send_key_to_window("ì§„ë£Œì‹¤", "enter")
    send_text_to_window("ì§„ë£Œì‹¤", text)
    send_key_to_window("ì§„ë£Œì‹¤", "enter")

def trim_special(s: str) -> str:
    # ì•ìª½ íŠ¹ìˆ˜ë¬¸ì ì œê±°
    s = re.sub(r'^\W+', '', s, flags=re.UNICODE)
    # ë’¤ìª½ íŠ¹ìˆ˜ë¬¸ì ì œê±°
    s = re.sub(r'\W+$', '', s, flags=re.UNICODE)
    return s

def update_summary_buttons():
    for w in summary_frame.winfo_children():
        w.destroy()
    if not summaries:
        tk.Label(summary_frame, text="No summary", font=("Arial", 10), fg="#666").pack()
        return
    total_line=0
    for idx, text in enumerate(list(summaries)):
        lines = [line.strip() for line in text.splitlines() if line.strip()]
        for line in lines:
            line = trim_special(line)
            if len(line) < 5:continue
            if total_line>=MAX_SUM:continue
            display = line if len(line) <= 120 else line[:120] + "..."
            total_line+=1
            btn = tk.Button(
                summary_frame,
                text=display.strip() or "",
                anchor="w",
                justify="left",
                wraplength=450,
                width=90,
                height=1,
                padx=0,
                pady=0,
                bd=1,
                relief='flat',
                command=lambda t=line: on_copy(t)
            )
            btn.pack(fill="x", padx=0,pady=0)

# ë…¹ìŒ ì‹œì‘
threading.Thread(target=record_loop, daemon=True).start()
root.after(500, update_window_title)


def on_close():
    save_window_position()
    global recording
    recording = False
    root.destroy()
root.protocol("WM_DELETE_WINDOW", on_close)

root.mainloop()
